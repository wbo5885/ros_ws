#!/usr/bin/env python3
"""
æ”¹è¿›çš„ORB-SLAM3 AIæ¨¡å‹è®­ç»ƒè„šæœ¬
ä½¿ç”¨æ•°æ®å½’ä¸€åŒ–å’Œæ”¹è¿›çš„æŸå¤±å‡½æ•°
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import cv2
import json
import os
from typing import Dict, List
import logging
from datetime import datetime

class ImprovedSLAMDataset(Dataset):
    """æ”¹è¿›çš„SLAMæ•°æ®é›†ï¼Œå¸¦æ•°æ®å½’ä¸€åŒ–"""
    
    def __init__(self, data_dir: str):
        self.data_dir = data_dir
        self.samples = self._load_samples()
        self.param_stats = self._calculate_param_stats()
        
    def _load_samples(self) -> List[Dict]:
        """åŠ è½½è®­ç»ƒæ ·æœ¬"""
        samples = []
        data_file = os.path.join(self.data_dir, 'training_data.json')
        
        if os.path.exists(data_file):
            with open(data_file, 'r') as f:
                samples = json.load(f)
        
        return samples
    
    def _calculate_param_stats(self):
        """è®¡ç®—å‚æ•°ç»Ÿè®¡ä¿¡æ¯ç”¨äºå½’ä¸€åŒ–"""
        if not self.samples:
            return None
            
        params = [sample['optimal_params'] for sample in self.samples]
        params = np.array(params)
        
        return {
            'mean': np.mean(params, axis=0),
            'std': np.std(params, axis=0) + 1e-8  # é¿å…é™¤é›¶
        }
    
    def normalize_params(self, params):
        """å½’ä¸€åŒ–å‚æ•°"""
        if self.param_stats is None:
            return params
        return (params - self.param_stats['mean']) / self.param_stats['std']
    
    def denormalize_params(self, normalized_params):
        """åå½’ä¸€åŒ–å‚æ•°"""
        if self.param_stats is None:
            return normalized_params
        return normalized_params * self.param_stats['std'] + self.param_stats['mean']
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        image_path = os.path.join(self.data_dir, sample['image_path'])
        image = cv2.imread(image_path)
        if image is None:
            # åˆ›å»ºè™šæ‹Ÿå›¾åƒä½œä¸ºå¤‡ç”¨
            image = np.random.randint(0, 255, (240, 320, 3), dtype=np.uint8)
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # å›¾åƒé¢„å¤„ç†
        image = cv2.resize(image, (64, 64))
        image = image.astype(np.float32) / 255.0
        image = np.transpose(image, (2, 0, 1))  # CHWæ ¼å¼
        
        # ç¯å¢ƒç‰¹å¾å½’ä¸€åŒ–
        env_features = np.array(sample['env_features'], dtype=np.float32)
        env_features = np.clip(env_features, 0, 10)  # é™åˆ¶èŒƒå›´
        
        # ç›®æ ‡å‚æ•°å½’ä¸€åŒ–
        target_params = np.array(sample['optimal_params'], dtype=np.float32)
        target_params = self.normalize_params(target_params)
        
        return {
            'image': torch.tensor(image),
            'env_features': torch.tensor(env_features),
            'target_params': torch.tensor(target_params),
            'performance_score': sample['performance_score']
        }

class ImprovedSLAMNetwork(nn.Module):
    """æ”¹è¿›çš„SLAMå‚æ•°é¢„æµ‹ç½‘ç»œ"""
    
    def __init__(self, env_feature_dim=8, output_dim=8):
        super().__init__()
        
        # CNNç‰¹å¾æå–å™¨
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((4, 4)),
            
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 256),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # å‚æ•°é¢„æµ‹ç½‘ç»œ
        self.param_predictor = nn.Sequential(
            nn.Linear(256 + env_feature_dim, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.2),
            
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.1),
            
            nn.Linear(64, output_dim)
            # ä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼Œè®©æ¨¡å‹å­¦ä¹ ä»»æ„èŒƒå›´çš„è¾“å‡º
        )
    
    def forward(self, image, env_features):
        # æå–å›¾åƒç‰¹å¾
        img_features = self.feature_extractor(image)
        
        # ç»„åˆç‰¹å¾
        combined_features = torch.cat([img_features, env_features], dim=1)
        
        # é¢„æµ‹å‚æ•°è°ƒæ•´
        param_adjustments = self.param_predictor(combined_features)
        
        return param_adjustments

def improved_train():
    """æ”¹è¿›çš„è®­ç»ƒå‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ”¹è¿›çš„AIæ¨¡å‹è®­ç»ƒ...")
    
    # è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    data_dir = '/home/wb/ros_ws/slam_training_data'
    model_save_dir = '/home/wb/ros_ws/src/orb_slam3_ai/models/trained'
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(model_save_dir, exist_ok=True)
    
    # æ•°æ®é›†
    dataset = ImprovedSLAMDataset(data_dir)
    print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)} æ ·æœ¬")
    
    if len(dataset) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®")
        return
    
    # æ‰“å°å‚æ•°ç»Ÿè®¡ä¿¡æ¯
    if dataset.param_stats:
        print("ğŸ“ˆ å‚æ•°ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  å‡å€¼: {dataset.param_stats['mean']}")
        print(f"  æ ‡å‡†å·®: {dataset.param_stats['std']}")
    
    # æ•°æ®åŠ è½½å™¨
    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
    
    # æ¨¡å‹
    model = ImprovedSLAMNetwork().to(device)
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)
    
    # ä½¿ç”¨Huber Lossï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’
    criterion = nn.SmoothL1Loss()
    
    print("ğŸ‹ï¸ å¼€å§‹è®­ç»ƒ...")
    
    # è®­ç»ƒå¾ªç¯
    num_epochs = 100
    best_loss = float('inf')
    
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        num_batches = 0
        
        for batch in dataloader:
            images = batch['image'].to(device)
            env_features = batch['env_features'].to(device)
            target_params = batch['target_params'].to(device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            predicted_params = model(images, env_features)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(predicted_params, target_params)
            
            # åå‘ä¼ æ’­
            loss.backward()
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            total_loss += loss.item()
            num_batches += 1
        
        avg_loss = total_loss / num_batches if num_batches > 0 else 0
        scheduler.step(avg_loss)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_loss < best_loss:
            best_loss = avg_loss
            best_model_path = os.path.join(model_save_dir, 'best_slam_model.pth')
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'model_config': {
                    'env_feature_dim': 8,
                    'output_dim': 8,
                    'model_type': 'ImprovedSLAMNetwork'
                },
                'param_stats': dataset.param_stats,
                'training_info': {
                    'epoch': epoch + 1,
                    'best_loss': best_loss,
                    'dataset_size': len(dataset),
                    'timestamp': datetime.now().isoformat()
                }
            }, best_model_path)
        
        if (epoch + 1) % 20 == 0:
            current_lr = optimizer.param_groups[0]['lr']
            print(f"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}, LR: {current_lr:.2e}, Best: {best_loss:.6f}")
    
    print(f"âœ… è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {best_model_path}")
    print(f"ğŸ“Š æœ€ä½³æŸå¤±: {best_loss:.6f}")
    
    # æµ‹è¯•æ¨¡å‹
    print("\nğŸ§ª æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹...")
    model.eval()
    test_losses = []
    
    with torch.no_grad():
        for i in range(min(5, len(dataset))):  # æµ‹è¯•å‰5ä¸ªæ ·æœ¬
            test_sample = dataset[i]
            test_image = test_sample['image'].unsqueeze(0).to(device)
            test_env = test_sample['env_features'].unsqueeze(0).to(device)
            test_target = test_sample['target_params'].unsqueeze(0).to(device)
            
            prediction = model(test_image, test_env)
            test_loss = criterion(prediction, test_target).item()
            test_losses.append(test_loss)
            
            # åå½’ä¸€åŒ–è¿›è¡Œå¯è§†åŒ–
            pred_denorm = dataset.denormalize_params(prediction.squeeze().cpu().numpy())
            target_denorm = dataset.denormalize_params(test_target.squeeze().cpu().numpy())
            
            print(f"\næ ·æœ¬ {i+1}:")
            print(f"  ç›®æ ‡å‚æ•°: {target_denorm}")
            print(f"  é¢„æµ‹å‚æ•°: {pred_denorm}")
            print(f"  ç›¸å¯¹è¯¯å·®: {np.mean(np.abs((pred_denorm - target_denorm) / (target_denorm + 1e-8))) * 100:.2f}%")
    
    print(f"\nğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
    print(f"  å¹³å‡æµ‹è¯•æŸå¤±: {np.mean(test_losses):.6f}")
    print(f"  æµ‹è¯•æŸå¤±æ ‡å‡†å·®: {np.std(test_losses):.6f}")

if __name__ == '__main__':
    improved_train()
#!/usr/bin/env python3
"""
ä»ä»¿çœŸç¯å¢ƒç”ŸæˆORB-SLAM3 AIè®­ç»ƒæ•°æ®
ä½¿ç”¨å½“å‰çš„ROS2æœºå™¨äººç³»ç»Ÿæ”¶é›†è®­ç»ƒæ ·æœ¬
"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, LaserScan
from geometry_msgs.msg import Twist, PoseStamped
from nav_msgs.msg import Odometry
import cv2
import numpy as np
import json
import os
import time
from datetime import datetime
from pathlib import Path
from cv_bridge import CvBridge
import threading
import random

class TrainingDataCollector(Node):
    """è®­ç»ƒæ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self):
        super().__init__('training_data_collector')
        
        # åˆå§‹åŒ–CV Bridge
        self.bridge = CvBridge()
        
        # æ•°æ®ä¿å­˜ç›®å½•
        self.data_dir = Path('/home/wb/ros_ws/slam_training_data/simulation_data')
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        (self.data_dir / 'images').mkdir(exist_ok=True)
        (self.data_dir / 'depth').mkdir(exist_ok=True)
        
        # è®¢é˜…ä¼ æ„Ÿå™¨è¯é¢˜
        self.rgb_sub = self.create_subscription(
            Image, '/camera/image_raw', self.rgb_callback, 10)
        self.depth_sub = self.create_subscription(
            Image, '/camera/depth/image_raw', self.depth_callback, 10)
        self.laser_sub = self.create_subscription(
            LaserScan, '/scan', self.laser_callback, 10)
        self.odom_sub = self.create_subscription(
            Odometry, '/odom', self.odom_callback, 10)
        
        # å‘å¸ƒè¿åŠ¨æ§åˆ¶
        self.cmd_pub = self.create_publisher(Twist, '/cmd_vel', 10)
        
        # æ•°æ®å­˜å‚¨
        self.latest_rgb = None
        self.latest_depth = None
        self.latest_laser = None
        self.latest_odom = None
        
        # è®­ç»ƒæ ·æœ¬
        self.training_samples = []
        self.sample_count = 0
        
        # æ”¶é›†å‚æ•°
        self.collection_interval = 2.0  # æ¯2ç§’æ”¶é›†ä¸€ä¸ªæ ·æœ¬
        self.max_samples = 500  # æœ€å¤§æ ·æœ¬æ•°
        
        # è¿åŠ¨æ¨¡å¼
        self.motion_patterns = [
            {'linear': 0.2, 'angular': 0.0, 'duration': 3.0, 'env_type': 'normal'},
            {'linear': 0.0, 'angular': 0.3, 'duration': 2.0, 'env_type': 'fast_motion'},
            {'linear': 0.1, 'angular': 0.1, 'duration': 4.0, 'env_type': 'normal'},
            {'linear': 0.0, 'angular': 0.0, 'duration': 2.0, 'env_type': 'static'},
            {'linear': -0.1, 'angular': 0.0, 'duration': 2.0, 'env_type': 'normal'},
        ]
        
        self.current_motion_idx = 0
        self.motion_start_time = time.time()
        
        # åˆ›å»ºå®šæ—¶å™¨
        self.collection_timer = self.create_timer(self.collection_interval, self.collect_sample)
        self.motion_timer = self.create_timer(0.1, self.update_motion)
        
        self.get_logger().info("ğŸš€ è®­ç»ƒæ•°æ®æ”¶é›†å™¨å¯åŠ¨")
        self.get_logger().info(f"ğŸ“ æ•°æ®ä¿å­˜åˆ°: {self.data_dir}")
    
    def rgb_callback(self, msg):
        """RGBå›¾åƒå›è°ƒ"""
        try:
            self.latest_rgb = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
        except Exception as e:
            self.get_logger().warn(f"RGBè½¬æ¢å¤±è´¥: {e}")
    
    def depth_callback(self, msg):
        """æ·±åº¦å›¾åƒå›è°ƒ"""
        try:
            self.latest_depth = self.bridge.imgmsg_to_cv2(msg, 'passthrough')
        except Exception as e:
            self.get_logger().warn(f"æ·±åº¦å›¾è½¬æ¢å¤±è´¥: {e}")
    
    def laser_callback(self, msg):
        """æ¿€å…‰é›·è¾¾å›è°ƒ"""
        self.latest_laser = msg
    
    def odom_callback(self, msg):
        """é‡Œç¨‹è®¡å›è°ƒ"""
        self.latest_odom = msg
    
    def update_motion(self):
        """æ›´æ–°æœºå™¨äººè¿åŠ¨"""
        if self.sample_count >= self.max_samples:
            return
        
        current_time = time.time()
        motion = self.motion_patterns[self.current_motion_idx]
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢è¿åŠ¨æ¨¡å¼
        if current_time - self.motion_start_time > motion['duration']:
            self.current_motion_idx = (self.current_motion_idx + 1) % len(self.motion_patterns)
            self.motion_start_time = current_time
            motion = self.motion_patterns[self.current_motion_idx]
            
            self.get_logger().info(f"ğŸ”„ åˆ‡æ¢è¿åŠ¨æ¨¡å¼: {motion}")
        
        # å‘å¸ƒè¿åŠ¨å‘½ä»¤
        cmd = Twist()
        cmd.linear.x = motion['linear']
        cmd.angular.z = motion['angular']
        self.cmd_pub.publish(cmd)
    
    def collect_sample(self):
        """æ”¶é›†ä¸€ä¸ªè®­ç»ƒæ ·æœ¬"""
        if self.sample_count >= self.max_samples:
            self.get_logger().info(f"âœ… è¾¾åˆ°æœ€å¤§æ ·æœ¬æ•°: {self.max_samples}")
            self.save_training_data()
            rclpy.shutdown()
            return
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if not all([self.latest_rgb is not None, 
                   self.latest_depth is not None,
                   self.latest_laser is not None,
                   self.latest_odom is not None]):
            self.get_logger().warn("âš ï¸ ä¼ æ„Ÿå™¨æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡æ­¤æ ·æœ¬")
            return
        
        try:
            # ç”Ÿæˆæ ·æœ¬ID
            sample_id = f"sim_{self.sample_count:04d}_{int(time.time())}"
            
            # ä¿å­˜å›¾åƒ
            rgb_filename = f"{sample_id}_rgb.png"
            depth_filename = f"{sample_id}_depth.png"
            
            cv2.imwrite(str(self.data_dir / 'images' / rgb_filename), self.latest_rgb)
            cv2.imwrite(str(self.data_dir / 'depth' / depth_filename), self.latest_depth)
            
            # åˆ†æç¯å¢ƒç‰¹å¾
            env_features = self.analyze_environment_features()
            
            # è·å–å½“å‰è¿åŠ¨çŠ¶æ€
            motion = self.motion_patterns[self.current_motion_idx]
            env_type = motion['env_type']
            
            # ç”ŸæˆSLAMå‚æ•° (åŸºäºç¯å¢ƒç±»å‹)
            optimal_params = self.generate_optimal_params(env_type, env_features)
            
            # è®¡ç®—æ€§èƒ½è¯„åˆ† (åŸºäºç‰¹å¾è´¨é‡)
            performance_score = self.calculate_performance_score(env_features)
            
            # åˆ›å»ºè®­ç»ƒæ ·æœ¬
            sample = {
                "sample_id": sample_id,
                "image_path": f"images/{rgb_filename}",
                "depth_path": f"depth/{depth_filename}",
                "timestamp": time.time(),
                "env_features": env_features,
                "optimal_params": optimal_params,
                "performance_score": performance_score,
                "scene_type": env_type,
                "motion_type": self.get_motion_type(motion),
                "robot_pose": self.get_robot_pose(),
                "laser_stats": self.get_laser_stats()
            }
            
            self.training_samples.append(sample)
            self.sample_count += 1
            
            self.get_logger().info(f"ğŸ“Š æ”¶é›†æ ·æœ¬ {self.sample_count}/{self.max_samples}: {env_type}, æ€§èƒ½={performance_score:.3f}")
            
            # å®šæœŸä¿å­˜æ•°æ®
            if self.sample_count % 50 == 0:
                self.save_training_data()
                
        except Exception as e:
            self.get_logger().error(f"âŒ æ”¶é›†æ ·æœ¬å¤±è´¥: {e}")
    
    def analyze_environment_features(self) -> list:
        """åˆ†æç¯å¢ƒç‰¹å¾"""
        gray = cv2.cvtColor(self.latest_rgb, cv2.COLOR_BGR2GRAY)
        
        # äº®åº¦
        brightness = np.mean(gray) / 255.0
        
        # å¯¹æ¯”åº¦
        contrast = np.std(gray) / 255.0
        
        # çº¹ç†å¯†åº¦
        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        texture_density = np.mean(edge_magnitude) / 255.0
        
        # è¿åŠ¨å¹…åº¦ (ä»é‡Œç¨‹è®¡)
        if self.latest_odom:
            motion_magnitude = abs(self.latest_odom.twist.twist.linear.x)
            angular_velocity = abs(self.latest_odom.twist.twist.angular.z)
        else:
            motion_magnitude = 0.0
            angular_velocity = 0.0
        
        # è¾¹ç¼˜å¯†åº¦
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
        
        # ç‰¹å¾ç‚¹å¯†åº¦
        orb = cv2.ORB_create()
        keypoints = orb.detect(gray, None)
        feature_density = len(keypoints) / 1000.0
        
        # ç¨³å®šæ€§ (åŸºäºå›¾åƒè´¨é‡å’Œè¿åŠ¨)
        stability = min(1.0, contrast * 2.0) * (1.0 - motion_magnitude)
        
        return [
            brightness,
            contrast,
            texture_density,
            motion_magnitude,
            angular_velocity,
            edge_density,
            feature_density,
            stability
        ]
    
    def generate_optimal_params(self, env_type: str, env_features: list) -> list:
        """æ ¹æ®ç¯å¢ƒç±»å‹å’Œç‰¹å¾ç”Ÿæˆæœ€ä¼˜SLAMå‚æ•°"""
        base_configs = {
            'normal': [1000, 1.2, 8, 0.75, 0.9, 0.25, 0.05, 3],
            'high_texture': [1200, 1.25, 8, 0.7, 0.9, 0.3, 0.05, 4],
            'low_texture': [600, 1.1, 6, 0.85, 0.8, 0.2, 0.1, 2],
            'low_light': [500, 1.15, 6, 0.8, 0.75, 0.25, 0.08, 3],
            'fast_motion': [1000, 1.2, 7, 0.75, 0.85, 0.35, 0.06, 3],
            'static': [800, 1.15, 7, 0.8, 0.95, 0.2, 0.04, 4]
        }
        
        base_params = base_configs.get(env_type, base_configs['normal'])
        
        # æ ¹æ®ç¯å¢ƒç‰¹å¾è¿›è¡Œå¾®è°ƒ
        brightness, contrast, texture_density = env_features[:3]
        
        adjusted_params = base_params.copy()
        
        # æ ¹æ®äº®åº¦è°ƒæ•´
        if brightness < 0.3:  # ä½å…‰ç…§
            adjusted_params[0] = max(400, adjusted_params[0] * 0.8)  # å‡å°‘ç‰¹å¾ç‚¹
            adjusted_params[3] = min(0.9, adjusted_params[3] + 0.1)  # æé«˜é˜ˆå€¼
        
        # æ ¹æ®çº¹ç†å¯†åº¦è°ƒæ•´
        if texture_density > 0.5:  # é«˜çº¹ç†
            adjusted_params[0] = min(1500, adjusted_params[0] * 1.2)  # å¢åŠ ç‰¹å¾ç‚¹
            adjusted_params[1] = min(1.3, adjusted_params[1] + 0.05)  # å¢åŠ å°ºåº¦å› å­
        
        # æ·»åŠ å°å¹…éšæœºæ‰°åŠ¨å¢åŠ æ•°æ®å¤šæ ·æ€§
        for i in range(len(adjusted_params)):
            noise = np.random.normal(0, 0.03)  # 3%å™ªå£°
            adjusted_params[i] = max(0.1, adjusted_params[i] * (1 + noise))
        
        return adjusted_params
    
    def calculate_performance_score(self, env_features: list) -> float:
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        brightness, contrast, texture_density, motion, angular_vel, edge_density, feature_density, stability = env_features
        
        # åŸºç¡€è¯„åˆ†
        base_score = 0.7
        
        # å›¾åƒè´¨é‡è¯„åˆ†
        image_quality = (contrast * 0.4 + texture_density * 0.3 + edge_density * 0.3)
        
        # è¿åŠ¨ç¨³å®šæ€§è¯„åˆ†
        motion_stability = max(0, 1.0 - motion * 2.0 - angular_vel * 1.5)
        
        # ç‰¹å¾ä¸°å¯Œåº¦è¯„åˆ†
        feature_richness = min(1.0, feature_density)
        
        # ç»¼åˆè¯„åˆ†
        total_score = base_score + image_quality * 0.2 + motion_stability * 0.1 + feature_richness * 0.1
        
        return min(1.0, max(0.0, total_score))
    
    def get_motion_type(self, motion: dict) -> str:
        """è·å–è¿åŠ¨ç±»å‹"""
        if motion['linear'] == 0 and motion['angular'] == 0:
            return 'static'
        elif abs(motion['linear']) > 0.15:
            return 'fast_translation'
        elif abs(motion['angular']) > 0.25:
            return 'fast_rotation'
        else:
            return 'slow_motion'
    
    def get_robot_pose(self) -> dict:
        """è·å–æœºå™¨äººä½å§¿"""
        if self.latest_odom:
            pose = self.latest_odom.pose.pose
            return {
                'x': pose.position.x,
                'y': pose.position.y,
                'z': pose.position.z,
                'qx': pose.orientation.x,
                'qy': pose.orientation.y,
                'qz': pose.orientation.z,
                'qw': pose.orientation.w
            }
        return {}
    
    def get_laser_stats(self) -> dict:
        """è·å–æ¿€å…‰é›·è¾¾ç»Ÿè®¡"""
        if self.latest_laser:
            ranges = np.array(self.latest_laser.ranges)
            valid_ranges = ranges[np.isfinite(ranges) & (ranges > 0)]
            
            return {
                'min_range': float(np.min(valid_ranges)) if len(valid_ranges) > 0 else 0.0,
                'max_range': float(np.max(valid_ranges)) if len(valid_ranges) > 0 else 0.0,
                'mean_range': float(np.mean(valid_ranges)) if len(valid_ranges) > 0 else 0.0,
                'std_range': float(np.std(valid_ranges)) if len(valid_ranges) > 0 else 0.0,
                'valid_points': len(valid_ranges),
                'total_points': len(ranges)
            }
        return {}
    
    def save_training_data(self):
        """ä¿å­˜è®­ç»ƒæ•°æ®"""
        if not self.training_samples:
            return
        
        # ä¿å­˜JSONæ–‡ä»¶
        output_file = self.data_dir / 'training_data.json'
        with open(output_file, 'w') as f:
            json.dump(self.training_samples, f, indent=2)
        
        # åˆ›å»ºæ•°æ®é›†ä¿¡æ¯
        dataset_info = {
            'created_at': datetime.now().isoformat(),
            'total_samples': len(self.training_samples),
            'data_directory': str(self.data_dir),
            'collection_parameters': {
                'collection_interval': self.collection_interval,
                'max_samples': self.max_samples,
                'motion_patterns': self.motion_patterns
            },
            'statistics': self.calculate_dataset_statistics()
        }
        
        info_file = self.data_dir / 'dataset_info.json'
        with open(info_file, 'w') as f:
            json.dump(dataset_info, f, indent=2)
        
        self.get_logger().info(f"ğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜:")
        self.get_logger().info(f"   æ ·æœ¬æ•°: {len(self.training_samples)}")
        self.get_logger().info(f"   æ•°æ®æ–‡ä»¶: {output_file}")
        self.get_logger().info(f"   ä¿¡æ¯æ–‡ä»¶: {info_file}")
    
    def calculate_dataset_statistics(self) -> dict:
        """è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        if not self.training_samples:
            return {}
        
        scene_types = {}
        motion_types = {}
        total_score = 0
        
        for sample in self.training_samples:
            scene_type = sample['scene_type']
            motion_type = sample['motion_type']
            
            scene_types[scene_type] = scene_types.get(scene_type, 0) + 1
            motion_types[motion_type] = motion_types.get(motion_type, 0) + 1
            total_score += sample['performance_score']
        
        return {
            'scene_type_distribution': scene_types,
            'motion_type_distribution': motion_types,
            'average_performance_score': total_score / len(self.training_samples),
            'total_samples': len(self.training_samples)
        }

def main():
    rclpy.init()
    
    try:
        collector = TrainingDataCollector()
        
        print("ğŸš€ å¼€å§‹ä»ä»¿çœŸç¯å¢ƒæ”¶é›†è®­ç»ƒæ•°æ®...")
        print("   - æœºå™¨äººå°†è‡ªåŠ¨æ‰§è¡Œå„ç§è¿åŠ¨æ¨¡å¼")
        print("   - æ¯2ç§’æ”¶é›†ä¸€ä¸ªè®­ç»ƒæ ·æœ¬")
        print("   - é¢„è®¡æ”¶é›†500ä¸ªæ ·æœ¬")
        print("   - æŒ‰Ctrl+Cæå‰åœæ­¢")
        
        rclpy.spin(collector)
        
    except KeyboardInterrupt:
        print("\\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ”¶é›†")
    except Exception as e:
        print(f"\\nâŒ æ”¶é›†è¿‡ç¨‹å‡ºé”™: {e}")
    finally:
        if 'collector' in locals():
            collector.save_training_data()
        rclpy.shutdown()

if __name__ == '__main__':
    main()